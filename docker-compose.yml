services:
  sd:
    build: .
    image: stable-diffusion:latest
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      # Mount code for live changes
      - ./generate.py:/app/generate.py:ro
      - ./generate_sdxl.py:/app/generate_sdxl.py:ro
      # Output images to host
      - ./output:/app/output
      # Cache models on host to avoid re-downloading
      - sd-models:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Override for interactive use
    stdin_open: true
    tty: true

  # SDXL base + refiner (best quality, needs ~14GB VRAM)
  sdxl:
    build: .
    image: stable-diffusion:latest
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      # Mount code for live changes
      - ./generate.py:/app/generate.py:ro
      - ./generate_sdxl.py:/app/generate_sdxl.py:ro
      - ./output:/app/output
      - sd-models:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    entrypoint: ["python3", "generate_sdxl.py"]
    stdin_open: true
    tty: true

  # API-based generation (no GPU needed)
  api:
    build: .
    image: stable-diffusion:latest
    environment:
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      - ./generate_api.py:/app/generate_api.py:ro
      - ./output:/app/output
    entrypoint: ["python3", "generate_api.py"]
    stdin_open: true
    tty: true

volumes:
  sd-models:
    name: stable-diffusion-models
